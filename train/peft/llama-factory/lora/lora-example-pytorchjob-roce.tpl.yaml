apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: ${JOB_NAME}
spec:
  nprocPerNode: "${GPUS_PER_NODE}"
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: cloud.ebtech.com/gpu # GPU节点的标签
                        operator: In
                        values:
                          - ${GPU_SPEC}
                      - key: node-role.kubernetes.io/zhaoxin-exclusive
                        operator: Exists
          tolerations:
            - key: node-role.ebtech.com/zhaoxin-exclusive
              operator: Equal
              value: "true"
              effect: NoSchedule
          containers:
            - command:
                - bash
                - -xc
                # - sleep infinity
                - /workspace/script.sh
              env:
                - name: MODEL_NAME
                  value: ${MODEL_NAME}
                - name: GPUS_PER_NODE
                  value: "${GPUS_PER_NODE}"
                - name: JOB_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: EPOCHS
                  value: "${EPOCHS}"
                - name: TRAIN_BATCH_SIZE_PER_DEVICE
                  value: "${TRAIN_BATCH_SIZE_PER_DEVICE}"
                - name: DATASET_DIR
                  value: "/data/datasets"
                - name: DATASET_TEMPLATE
                  value: "${DATASET_TEMPLATE}"
                - name: TZ
                  value: Asia/Shanghai
                - name: REPORT_TO
                  value: "${REPORT_TO}"
                - name: LOGGING_DIR
                  value: "${LOGGING_DIR}"
                - name: NCCL_IB_DISABLE
                  value: "${NCCL_IB_DISABLE}"
                - name: NCCL_DEBUG
                  value: "${NCCL_DEBUG}"
                - name: NCCL_SOCKET_IFNAME
                  value: "${NCCL_SOCKET_IFNAME}"
                - name: CUDA_VISIBLE_DEVICES
                  value: "${GPUS_INDICES}"
                - name: NCCL_NET
                  value: "${NCCL_NET}"
              image: ${IMAGE_NAME}
              imagePullPolicy: Always
              name: pytorch
              ports:
                - name: pytorchjob-port
                  containerPort: ${MASTER_PORT}
                  protocol: TCP
              resources:
                limits:
                  cpu: "${CPU_RESOURCES_LIMITS}"
                  memory: "${MEM_RESOURCES_LIMITS}"
                  nvidia.com/gpu: "${GPUS_PER_NODE}"
                  rdma/hca_shared_devices_ib: "${HCA_SHARED_DEVICES}"
                requests:
                  cpu: "${CPU_RESOURCES_REQS}"
                  memory: "${MEM_RESOURCES_REQS}"
                  nvidia.com/gpu: "${GPUS_PER_NODE}"
                  rdma/hca_shared_devices_ib: "${HCA_SHARED_DEVICES}"
              securityContext:
                privileged: true
                capabilities:
                  add: ["IPC_LOCK", "NET_ADMIN", "NET_RAW", "NET_BIND_SERVICE"]
              volumeMounts:
                - name: public
                  mountPath: /data/models
                  subPath: huggingface-models
                - mountPath: /dev/shm
                  name: dshm
                - name: dataset
                  mountPath: /data/datasets/identity.json
                  subPath: identity.json
                  readOnly: true
                - name: dataset-info
                  mountPath: /data/datasets/dataset_info.json
                  subPath: dataset_info.json
                  readOnly: true
                - name: hf-cache
                  mountPath: /root/.cache/huggingface
                - name: model-cache
                  mountPath: /root/.cache/modelscope
                - name: output
                  mountPath: /app/output
                - name: script
                  mountPath: /workspace
          hostIPC: true
          hostNetwork: true
          hostPID: true
          dnsPolicy: ClusterFirstWithHostNet
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 80Gi
            - name: dataset
              configMap:
                name: dataset
                items:
                  - key: identity.json
                    path: identity.json
            - name: dataset-info
              configMap:
                name: dataset-info
                items:
                  - key: dataset_info.json
                    path: dataset_info.json
            - name: hf-cache
              emptyDir: {}
            - name: model-cache
              emptyDir: {}
            - name: output
              emptyDir: {}
              #persistentVolumeClaim:
              #  claimName: example-output
            - name: public
              hostPath:
                path: /public
                type: DirectoryOrCreate
            - name: script
              configMap:
                name: script
                defaultMode: 0755
                items:
                  - key: script.sh
                    path: script.sh
    Worker:
      replicas: ${WORKER_NODES}
      restartPolicy: Never
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: cloud.ebtech.com/gpu # GPU节点的标签
                        operator: In
                        values:
                          - ${GPU_SPEC}
                      - key: node-role.kubernetes.io/zhaoxin-exclusive
                        operator: Exists
                # podAntiAffinity:
                #   preferredDuringSchedulingIgnoredDuringExecution:
                #     - weight: 100
                #       podAffinityTerm:
                #         labelSelector:
                #           matchExpressions:
                #             - key: training.kubeflow.org/job-name
                #               operator: In
                #               values:
                #                 - ${JOB_NAME}
                #         topologyKey: kubernetes.io/hostname
          tolerations:
            - key: node-role.ebtech.com/zhaoxin-exclusive
              operator: Equal
              value: "true"
              effect: NoSchedule
          containers:
            - command:
                - bash
                - -xc
                # - sleep infinity
                - /workspace/script.sh
              env:
                - name: GPUS_PER_NODE
                  value: "${GPUS_PER_NODE}"
                - name: MODEL_NAME
                  value: ${MODEL_NAME}
                - name: JOB_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: EPOCHS
                  value: "${EPOCHS}"
                - name: TRAIN_BATCH_SIZE_PER_DEVICE
                  value: "${TRAIN_BATCH_SIZE_PER_DEVICE}"
                - name: DATASET_DIR
                  value: "/data/datasets"
                - name: DATASET_TEMPLATE
                  value: "${DATASET_TEMPLATE}"
                - name: TZ
                  value: Asia/Shanghai
                - name: REPORT_TO
                  value: "${REPORT_TO}"
                - name: LOGGING_DIR
                  value: "${LOGGING_DIR}"
                - name: NCCL_IB_DISABLE
                  value: "${NCCL_IB_DISABLE}"
                - name: NCCL_DEBUG
                  value: "${NCCL_DEBUG}"
                - name: NCCL_SOCKET_IFNAME
                  value: "${NCCL_SOCKET_IFNAME}"
                - name: CUDA_VISIBLE_DEVICES
                  value: "${GPUS_INDICES}"
                - name: NCCL_NET
                  value: "${NCCL_NET}"
              image: ${IMAGE_NAME}
              imagePullPolicy: Always
              name: pytorch
              resources:
                limits:
                  cpu: "${CPU_RESOURCES_LIMITS}"
                  memory: "${MEM_RESOURCES_LIMITS}"
                  nvidia.com/gpu: "${GPUS_PER_NODE}"
                  rdma/hca_shared_devices_ib: "${HCA_SHARED_DEVICES}"
                requests:
                  cpu: "${CPU_RESOURCES_REQS}"
                  memory: "${MEM_RESOURCES_REQS}"
                  nvidia.com/gpu: "${GPUS_PER_NODE}"
                  rdma/hca_shared_devices_ib: "${HCA_SHARED_DEVICES}"
              ports:
                - name: pytorchjob-port
                  containerPort: ${MASTER_PORT}
                  protocol: TCP
              securityContext:
                privileged: true
                capabilities:
                  add: ["IPC_LOCK", "NET_ADMIN", "NET_RAW", "NET_BIND_SERVICE"]
              volumeMounts:
                - name: public
                  mountPath: /data/models
                  subPath: huggingface-models
                - mountPath: /dev/shm
                  name: dshm
                - name: dataset
                  mountPath: /data/datasets/identity.json
                  subPath: identity.json
                  readOnly: true
                - name: dataset-info
                  mountPath: /data/datasets/dataset_info.json
                  subPath: dataset_info.json
                  readOnly: true
                - name: hf-cache
                  mountPath: /root/.cache/huggingface
                - name: model-cache
                  mountPath: /root/.cache/modelscope
                - name: output
                  mountPath: /app/output
                - name: script
                  mountPath: /workspace
          hostIPC: true
          hostNetwork: true
          hostPID: true
          dnsPolicy: ClusterFirstWithHostNet
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 80Gi
            - name: dataset
              configMap:
                name: dataset
                items:
                  - key: identity.json
                    path: identity.json
            - name: dataset-info
              configMap:
                name: dataset-info
                items:
                  - key: dataset_info.json
                    path: dataset_info.json
            - name: hf-cache
              emptyDir: {}
            - name: model-cache
              emptyDir: {}
            - name: public
              hostPath:
                path: /public
                type: DirectoryOrCreate
            - name: output
              emptyDir: {}
            - name: script
              configMap:
                name: script
                defaultMode: 0755
                items:
                  - key: script.sh
                    path: script.sh

  runPolicy:
    cleanPodPolicy: None
    suspend: false
