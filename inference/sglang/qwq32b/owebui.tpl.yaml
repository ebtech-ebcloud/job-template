apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: owebui-data # 存储卷的名称
spec:
  accessModes:
    - ReadWriteMany # 存储卷的读写模式
  resources:
    requests:
      storage: 1Gi # 存储卷的容量大小
  storageClassName: shared-nvme-cn-huabei1 # 创建存储卷使用的StorageClass的名字

---

apiVersion: apps/v1

kind: Deployment
metadata:
  name: owebui-1
  namespace: default
  labels:
    app: owebui-1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: owebui-1
  template:
    metadata:
      labels:
        app: owebui-1
    spec:
      volumes:
        # 挂载共享模型数据大盘（如需要）
        - name: models
          hostPath:
            path: /public
        # 挂载分布式存储盘（如需要）
        - name: data
          persistentVolumeClaim:
            claimName: owebui-data
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "2Gi"
      containers:
      - name: owebui
        image: registry-cn-huabei1-internal.ebcloud.com/ghcr.io/open-webui/open-webui:ollama
        command:
          - bash
          - "-c"
          - |
            # pip install huggingface_hub[hf_xet] -i https://pypi.tuna.tsinghua.edu.cn/simple
            # prepare open-webui data dir
            mkdir -p /data/owebui-data/data
            rm -rf /app/backend/data
            ln -s /data/owebui-data/data /app/backend/

            # prepare ollama models dir
            mkdir -p /data/ollama-data
            rm -rf /root/.ollama
            ln -s /data/ollama-data /root/.ollama
            # echo "pulling  llama3.2:1b ..."
            # ollama pull llama3.2:1b
            
            # prepare open-webui secret key
            if [ ! -f /app/backend/data/.webui_secret_key ]; then
              echo $(head -c 12 /dev/random | base64) > /app/backend/data/.webui_secret_key
            fi
            ln -s /app/backend/data/.webui_secret_key /app/backend/.webui_secret_key
            
            # comment out lines containing "application/json" in images.py
            sed -i '/application\/json/s/^/#/' /app/backend/open_webui/routers/images.py
            
            # start open-webui
            bash /app/backend/start.sh
        env:
          - name: HF_ENDPOINT
            value: "https://hf-mirror.com"
          - name: ENABLE_EVALUATION_ARENA_MODELS
            value: "false"
          - name: RAG_EMBEDDING_MODEL
            value: "/public/huggingface-models/sentence-transformers/all-MiniLM-L6-v2"
          # - name: ENABLE_OPENAI_API # 不带模型服务(OpenAI_API_BASE_URL/OpenAI_API_BASE_URLS)启动时，取消掉这里的注释，以避免对 openai 官方 API 的依赖
          #   value: "false"
          - name: OPENAI_API_KEYS # 多个 API Key 用分号分隔
            value: "sk-foo-bar"
          - name: OPENAI_API_BASE_URLS # 多个 API Base URL 用分号分隔
            value: "http://qwq-32b-1/v1"
          - name: ENABLE_WEB_SEARCH
            value: "true"
          - name: WEB_SEARCH_ENGINE
            value: "searxng"
          - name: SEARXNG_QUERY_URL
            value: "http://searxng-1/search?q=<query>"
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: "2"
            memory: 4G
          requests:
            cpu: "2"
            memory: 4G
        volumeMounts:
        - name: shm
          mountPath: /dev/shm
        # 挂载共享模型数据大盘（如需要）
        - name: models
          mountPath: /public
        # 挂载分布式存储盘（如需要）
        - name: data
          mountPath: /data

---


apiVersion: v1
kind: Service
metadata:
  name: owebui-1
  namespace: default
spec:
  ports:
  - name: http-owebui-1
    port: 80
    protocol: TCP
    targetPort: 8080
  # The label selector should match the deployment labels & it is useful for prefix caching feature
  selector:
    app: owebui-1
  sessionAffinity: None
  # 指定 LoadBalancer 类型，用于将服务暴露到外部，自动分配公网 IP
  type: LoadBalancer
  # type: ClusterIP
